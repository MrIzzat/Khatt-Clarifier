{"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs:\", len(physical_devices))"],"metadata":{"id":"hznzyH8L7ijc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["physical_devices"],"metadata":{"id":"DzK40Tu_7xql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"id":"3Yn-Qi2T7uM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.backend import manual_variable_initialization\n","manual_variable_initialization(True)"],"metadata":{"id":"U21MgdgTfqOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%ls"],"metadata":{"id":"LQMrblmS_i0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd content/"],"metadata":{"id":"Xl3jR60T_lQR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip uninstall tensorflow\n","#!pip install tensorflow==2.15.0"],"metadata":{"id":"0vhj43CeOtC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKThngF7hCtY"},"outputs":[],"source":["#Data Fetching\n","!pip install opencv-contrib-python\n","from IPython.display import clear_output\n","#!unzip \"/content/Total Images.zip\" -d \"/content/\"\n","#!unzip \"/content/Total GT.zip\" -d \"/content/\"\n","#!unzip \"/content/Dataset.zip\" -d \"/content/\"\n","!unzip \"/content/img_aug.zip\" -d \"/content/\"\n","!unzip \"/content/labels_aug.zip\" -d \"/content/\"\n","#clear_output()"]},{"cell_type":"code","source":["!rm -rf /content/Dataset/"],"metadata":{"id":"cagOLW0C01X9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf \"/content/Full Dataset.zip\""],"metadata":{"id":"a6N5LGsg2xQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import clear_output\n","\n","!unzip \"/content/Full Dataset.zip\" -d \"/content/Dataset/\"\n","clear_output()"],"metadata":{"id":"TBVt0CoD0ZZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhzI1ZLchcd8"},"outputs":[],"source":["#Useful imports\n","#will remain the same\n","from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n","from tensorflow import keras\n","\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)"]},{"cell_type":"code","source":["#imagesDirectory = '/content/Dataset/Total Images'\n","imagesDirectory = '/content/Dataset/Full Dataset/Images'\n","\n","for imagePath in sorted(os.listdir(imagesDirectory)):\n","  if imagePath.split('.')[-1] == \"tif\":\n","    imageTif = cv.imread(imagesDirectory+\"/\"+imagePath, cv.IMREAD_UNCHANGED)\n","    #cv2_imshow(imageTif)\n","    newImagePath = imagePath.replace('.tif','.jpg')\n","    cv.imwrite(imagesDirectory+\"/\"+newImagePath,imageTif)\n","    os.remove(imagesDirectory+\"/\"+imagePath)"],"metadata":{"id":"ki1j4Gw7LnM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k5QaeNxhqT_"},"outputs":[],"source":["#filenames_img=sorted(os.listdir('/content/Dataset/Total Images'))\n","#filenames_gt=sorted(os.listdir('/content/Dataset/Total GT'))\n","\n","filenames_img=sorted(os.listdir('/content/Dataset/Full Dataset/Images'))\n","filenames_gt=sorted(os.listdir('/content/Dataset/Full Dataset/Labels'))\n","\n","#filenames_imgsplit=[filename.replace('.tif', '') for filename in filenames_img]\n","filenames_imgsplit=[filename.replace('.jpg', '') for filename in filenames_img]\n","#filenames_imgsplit=[filename.replace('.bmp', '') for filename in filenames_imgsplit]\n","\n","filenames_gtsplit=[filename.replace('.txt', '') for filename in filenames_gt]\n","\n","print(len(filenames_imgsplit))\n","print(len(filenames_gtsplit))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRDA2kaYhzX4"},"outputs":[],"source":[" #train test validate splitting\n","split_idx = int(0.8 * len(filenames_imgsplit))\n","train_samples = filenames_img[:split_idx]\n","train_samples_split = filenames_imgsplit[:split_idx]\n","test_samples = filenames_img[split_idx:]\n","test_samples_split = filenames_imgsplit[split_idx:]\n","\n","val_split_idx = int(0.5 * len(test_samples))\n","validation_samples = test_samples[:val_split_idx]\n","validation_samples_split = test_samples_split[:val_split_idx]\n","test_samples = test_samples[val_split_idx:]\n","test_samples_split = test_samples_split[val_split_idx:]\n","\n","assert len(filenames_imgsplit) == len(train_samples) + len(validation_samples) + len(\n","    test_samples\n",")\n","\n","print(f\"Total training samples: {len(train_samples)}\")\n","print(f\"Total validation samples: {len(validation_samples)}\")\n","print(f\"Total test samples: {len(test_samples)}\")\n","print(f' Example from training dataset {train_samples_split[0]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15RdGQJuilt6"},"outputs":[],"source":["#get data and labels as lists\n","#base_path='/content/Dataset/'\n","#base_image_path = os.path.join(base_path, \"Total Images/\")\n","#base_GT_path = os.path.join(base_path, \"Total GT/\")\n","\n","base_path='/content/Dataset/Full Dataset/'\n","base_image_path = os.path.join(base_path, \"Images/\")\n","base_GT_path = os.path.join(base_path, \"Labels/\")\n","\n","def get_image_paths_and_labels(filenames_img, filenames_imgsplit):\n","    paths = []\n","    labels = []\n","    for i in range(len(filenames_imgsplit)):\n","        img_path = os.path.join(\n","            base_image_path,  filenames_img[i]\n","        )\n","        if os.path.getsize(img_path):\n","            paths.append(img_path)\n","            label_path = os.path.join(\n","            base_GT_path,  filenames_imgsplit[i]+'.txt'\n","        )\n","        label_file = open(label_path, \"r\")\n","        labels.append(label_file.read())\n","\n","    return paths, labels\n","\n","train_img_paths, train_labels = get_image_paths_and_labels(train_samples, train_samples_split)\n","validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples, validation_samples_split)\n","test_img_paths, test_labels = get_image_paths_and_labels(test_samples, test_samples_split)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjrxJp1lqIaX"},"outputs":[],"source":[" # Find maximum length and the size of the vocabulary in the training data.\n","train_labels_cleaned = []\n","characters = set()\n","max_len = 0\n","\n","for label in train_labels:\n","    label = label.split(\" \")[-1].strip()\n","    for char in label:\n","        characters.add(char)\n","\n","    max_len = max(max_len, len(label))\n","    train_labels_cleaned.append(label)\n","\n","print(\"Maximum length: \", max_len)\n","print(\"Vocab size: \", len(characters))\n","\n","# Check some label samples.\n","train_labels_cleaned[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBSqAB2tqeoR"},"outputs":[],"source":["def clean_labels(labels):\n","    cleaned_labels = []\n","    for label in labels:\n","        label = label.split(\" \")[-1].strip()\n","        cleaned_labels.append(label)\n","    return cleaned_labels\n","\n","\n","validation_labels_cleaned = clean_labels(validation_labels)\n","test_labels_cleaned = clean_labels(test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoUQ7b9TT-Q-"},"outputs":[],"source":["print(characters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oy1gxSJMqonS"},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","# Mapping characters to integers.\n","char_to_num = StringLookup(vocabulary=list(sorted(characters)), mask_token=None)\n","\n","# Mapping integers back to original characters.\n","num_to_char = StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",")\n","\n","char_to_num.get_vocabulary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPIYYdhCqxfz"},"outputs":[],"source":["def distortion_free_resize(image, img_size):\n","    w, h = img_size\n","    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n","\n","    # Check tha amount of padding needed to be done.\n","    pad_height = h - tf.shape(image)[0]\n","    pad_width = w - tf.shape(image)[1]\n","\n","    # Only necessary if you want to do same amount of padding on both sides.\n","    if pad_height % 2 != 0:\n","        height = pad_height // 2\n","        pad_height_top = height + 1\n","        pad_height_bottom = height\n","    else:\n","        pad_height_top = pad_height_bottom = pad_height // 2\n","\n","    if pad_width % 2 != 0:\n","        width = pad_width // 2\n","        pad_width_left = width + 1\n","        pad_width_right = width\n","    else:\n","        pad_width_left = pad_width_right = pad_width // 2\n","\n","    image = tf.pad(\n","        image,\n","        paddings=[\n","            [pad_height_top, pad_height_bottom],\n","            [pad_width_left, pad_width_right],\n","            [0, 0],\n","        ],\n","    )\n","\n","    image = tf.transpose(image, perm=[1, 0, 2])\n","    image = tf.image.flip_left_right(image)\n","    return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yu3ZTSjyuaZD"},"outputs":[],"source":["print(train_labels_cleaned)"]},{"cell_type":"code","source":["len(train_labels_cleaned)"],"metadata":{"id":"vLl20vQwF4uY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFRBXqgKq4eN"},"outputs":[],"source":["batch_size = 64\n","padding_token = 99\n","image_width = 64\n","image_height = 32\n","\n","\n","def preprocess_image(image_path, img_size=(image_width, image_height)):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, 0)\n","\n","    image = distortion_free_resize(image, img_size)\n","\n","    image =  tf.where(image > 80, 255, 0)#Basic thresholding\n","\n","    image = tf.cast(image, tf.float32) / 255.0\n","\n","    return image\n","\n","\n","def vectorize_label(label):\n","    print(label)\n","    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n","    length = tf.shape(label)[0]\n","    pad_amount = max_len - length\n","    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n","    return label\n","\n","label=vectorize_label(train_labels_cleaned[0])\n","print(label)\n","indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n","label = tf.strings.reduce_join(num_to_char(indices))\n","label = label.numpy().decode(\"UTF-8\")\n","print(label)\n","\n","def process_images_labels(image_path, label):\n","    image = preprocess_image(image_path)\n","    label = vectorize_label(label)\n","    return {\"image\": image, \"label\": label}\n","\n","\n","def prepare_dataset(image_paths, labels):\n","    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n","        process_images_labels, num_parallel_calls=AUTOTUNE\n","    )\n","    return dataset.batch(batch_size).cache().prefetch(AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jIBy0L_rvszy"},"outputs":[],"source":["train_ds = prepare_dataset(train_img_paths, train_labels_cleaned)\n","validation_ds = prepare_dataset(validation_img_paths, validation_labels_cleaned)\n","test_ds = prepare_dataset(test_img_paths, test_labels_cleaned)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PrS10_qv4CQ"},"outputs":[],"source":["for data in test_ds.take(6):\n","    images, labels = data[\"image\"], data[\"label\"]\n","\n","    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n","\n","    for i in range(16):\n","        img = images[i]\n","        img = tf.image.flip_left_right(img)\n","        img = tf.transpose(img, perm=[1, 0, 2])\n","        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n","        img = img[:, :, 0]\n","\n","        # Gather indices where label!= padding_token.\n","        label = labels[i]\n","        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n","        # Convert to string.\n","        label = tf.strings.reduce_join(num_to_char(indices))\n","        label = label.numpy().decode(\"utf-8\")\n","\n","        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n","        ax[i // 4, i % 4].set_title(label[::-1])\n","        ax[i // 4, i % 4].axis(\"off\")\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E1hPZfai5M3q"},"outputs":[],"source":["class CTCLayer(keras.layers.Layer):\n","    def __init__(self, name=None):\n","        super().__init__(name=name)\n","        self.loss_fn = keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","        #print(\"True y:\",y_true)\n","        print(\"Pred y\", y_pred)\n","        # At test time, just return the computed predictions.\n","        #return y_pred\n","\n","\n","def build_model():\n","    # Inputs to the model\n","    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n","    labels = keras.layers.Input(name=\"label\", shape=(None,))\n","\n","    # First conv block.\n","    x = keras.layers.Conv2D(\n","        32,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv1\",\n","    )(input_img)\n","    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n","    x= keras.layers.BatchNormalization()(x)\n","\n","    #This CNN layer wasn't here originally\n","    x = keras.layers.Conv2D(\n","        64,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv2\",\n","    )(x)\n","    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n","    x= keras.layers.BatchNormalization()(x)\n","\n","    new_shape = ((image_width // 2), (image_height // 2) * 16)#was originally *32\n","    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n","\n","    x = keras.layers.Dense(16, activation=\"relu\", name=\"dense2\")(x)\n","    x= keras.layers.BatchNormalization()(x)\n","\n","    x = keras.layers.Bidirectional(\n","        keras.layers.LSTM(256, return_sequences=True, dropout=0.35))(x)\n","    x = keras.layers.Dense(\n","        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense3\"\n","    )(x)\n","\n","    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n","    #print(\"labels:\", labels)\n","    #print(x)\n","\n","    # Define the model.\n","    model = keras.models.Model(\n","        inputs=[input_img, labels], outputs=output, name=\"handwriting_recognizer\"\n","    )\n","    # Optimizer.\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.01,\n","    decay_steps=10000,\n","    decay_rate=0.9)\n","    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n","    # Compile the model and return.\n","    model.compile(optimizer=opt\n","                )\n","    return model\n","\n","\n","# Get the model.\n","model = build_model()\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvk3StRQ6OID"},"outputs":[],"source":["validation_images = []\n","validation_labels = []\n","\n","for batch in validation_ds:\n","    validation_images.append(batch[\"image\"])\n","    validation_labels.append(batch[\"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqXAS8Rp6Qi5"},"outputs":[],"source":["def calculate_edit_distance(labels, predictions):\n","    # Get a single batch and convert its labels to sparse tensors.\n","    sparse_labels = tf.sparse.from_dense(labels)\n","\n","    # Make predictions and convert them to sparse tensors.\n","    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n","\n","    predictions_decoded = keras.backend.ctc_decode(\n","\n","        predictions, input_length=input_len, greedy=False, beam_width=100,\n","    )[0][0][:, :max_len]\n","    sparse_predictions =tf.sparse.from_dense(predictions_decoded)\n","\n","    # Compute individual edit distances and average them out.\n","    edit_distances = tf.edit_distance(\n","        sparse_predictions, sparse_labels, normalize=False\n","    )\n","    return tf.reduce_mean(edit_distances)\n","\n","\n","class EditDistanceCallback(keras.callbacks.Callback):\n","    def __init__(self, pred_model):\n","        super().__init__()\n","        self.prediction_model = pred_model\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        edit_distances = []\n","\n","#         for i in range(len(validation_images)):\n","#             labels = validation_labels[i]\n","#             predictions = self.prediction_model.predict(validation_images[i],verbose=0)\n","#             #print(decode_batch_predictions(predictions))\n","# #            print(\"Prediction\")\n","# #            print(predictions)\n","# #            print(\"Labels:\")\n","# #            print(labels)\n","# #            print(\"----------------------\")\n","#             edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n","        #if epoch>300:\n","        #  getCharacterAccuracy(test_ds)#Get accuracy on dataset after every epoch but it's very slow (needs an extra 80% of the original time)\n","       # print(\n","       #     f\"\\nMean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n","       # )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41kEKtah6dMH"},"outputs":[],"source":["epochs = 450  # To get good results this should be at least 50.\n","\n","model = build_model()\n","prediction_model = keras.models.Model(\n","    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense3\").output\n",")\n","edit_distance_callback = EditDistanceCallback(prediction_model)\n","\n","stopping=tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\",\n","    min_delta=0,\n","    patience=3,\n","    verbose=0,\n","    mode=\"auto\",\n","    baseline=None,\n","    restore_best_weights=False,\n",")\n","\n","# Train the model.\n","history = model.fit(\n","    train_ds,\n","    validation_data=validation_ds,\n","    epochs=epochs,\n","    callbacks=[edit_distance_callback],\n","    shuffle=True\n",")\n","\n","#add early stopping mechanism"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqMD9_uV78IQ"},"outputs":[],"source":["# A utility function to decode the output of the network.\n","def decode_batch_predictions(pred):\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search.\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False)[0][0][\n","        :, :max_len\n","    ]\n","    # Iterate over the results and get back the text.\n","    output_text = []\n","    #print(results)\n","    for res in results:\n","        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"UTF-8\")\n","        output_text.append(res)\n","    #print(output_text)\n","\n","    return output_text"]},{"cell_type":"code","source":["#prediction_model = tf.keras.models.load_model('epochs1000.h5')"],"metadata":{"id":"1-k96LbboODn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrrOwwWt8IEH"},"outputs":[],"source":["#  Let's check results on some test samples.\n","for batch in test_ds.take(1):\n","  batch_images,batch_labels = batch[\"image\"],batch[\"label\"]\n","  _, ax = plt.subplots(4, 16, figsize=(40, 8))\n","\n","  preds = prediction_model.predict(batch_images)\n","  pred_texts = decode_batch_predictions(preds)\n","\n","\n","  for i in range(len(batch_images)):\n","        img = batch_images[i]\n","\n","        indices = tf.gather(batch_labels[i], tf.where(tf.math.not_equal(batch_labels[i], padding_token)))\n","        label = tf.strings.reduce_join(num_to_char(indices))\n","        label = label.numpy().decode(\"UTF-8\")\n","\n","        img = tf.image.flip_left_right(img)\n","        img = tf.transpose(img, perm=[1, 0, 2])\n","        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n","        img = img[:, :, 0]\n","\n","        title = f\"Prediction: {pred_texts[i][::-1]}\"\n","        #print(pred_texts[i]=='')\n","\n","        ax[i // 16, i % 16].imshow(img, cmap=\"gray\")\n","        ax[i // 16, i % 16].set_title(title)\n","        ax[i // 16, i % 16].set_xlabel(\"label: \"+label[::-1], labelpad=1)\n","        ax[i // 16, i % 16].axis(\"on\")\n","\n","\n","\n","\n","  plt.show()\n","\n"]},{"cell_type":"code","source":["plt.plot(history.history['val_loss'][2:len(history.history['val_loss'])-1])\n","plt.plot(history.history['loss'][2:len(history.history['loss'])-1]);"],"metadata":{"id":"FESxtfjtMwoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBy8QteZY4R2"},"outputs":[],"source":["plt.plot(history.history['val_loss'][1:len(history.history['val_loss'])-1])\n","plt.plot(history.history['loss'][1:len(history.history['loss'])-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktVZxM7MXdOb"},"outputs":[],"source":["plt.plot(history.history['val_loss'])\n","plt.plot(history.history['loss'])\n","plt.legend()"]},{"cell_type":"markdown","source":["##### Iterating through the labels"],"metadata":{"id":"nmmNQUUjdjOJ"}},{"cell_type":"code","source":["i=0\n","for batch in train_ds:\n","    batch_label = batch[\"label\"]\n","\n","    for Label in batch_label:\n","      indices = tf.gather(Label, tf.where(tf.math.not_equal(Label, padding_token)))\n","      label = tf.strings.reduce_join(num_to_char(indices))\n","      label = label.numpy().decode(\"UTF-8\")\n","      #print(label)\n","      i+=1\n","i"],"metadata":{"id":"6CZzh7CCTyiI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for data in test_ds.take(2):\n","    images, labels = data[\"image\"], data[\"label\"]\n","\n","    _, ax = plt.subplots(4, 4, figsize=(15, 8))\n","\n","    for i in range(16):\n","        img = images[i]\n","        img = tf.image.flip_left_right(img)\n","        img = tf.transpose(img, perm=[1, 0, 2])\n","        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n","        img = img[:, :, 0]\n","\n","        # Gather indices where label!= padding_token.\n","        label = labels[i]\n","        indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n","        # Convert to string.\n","        label = tf.strings.reduce_join(num_to_char(indices))\n","        label = label.numpy().decode(\"utf-8\")\n","\n","        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n","        ax[i // 4, i % 4].set_title(label[::-1])\n","        ax[i // 4, i % 4].axis(\"off\")\n","\n","\n","plt.show()"],"metadata":{"id":"RWf1CcWVch7W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Creating a character accuracy function\n","\n","Uses the formula:\n","\n","Character Error Rate (CER) = ( (insertions + subsitutions + deletions) / total character count ) * 100%"],"metadata":{"id":"xQJJMiyx9G9p"}},{"cell_type":"code","source":["def getCharacterAccuracy(test_ds):\n","    # for batch in test_ds.take(1):\n","\n","    totalCharacters = 0\n","    wrongCharacters = 0\n","    batchNumber = 0\n","\n","    for batch in test_ds:\n","        # batch = tuple(test_ds.take(1))[0]\n","        batchNumber += 1\n","        batch_images, batch_labels = batch[\"image\"], batch[\"label\"]\n","        preds = prediction_model.predict(batch_images,verbose=0)\n","        pred_texts = decode_batch_predictions(preds)\n","\n","        input_len = np.ones(preds.shape[0]) * preds.shape[1]\n","        # Use greedy search. For complex tasks, you can use beam search.\n","        results = keras.backend.ctc_decode(preds, input_length=input_len, greedy=True)[\n","            0\n","        ][0][:, :max_len]\n","\n","        AllPredictions = []\n","        # All predicitons\n","        for res in results:\n","            res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n","            res = tf.squeeze(res)\n","            norRes = tf.Variable(res)\n","\n","            # print(norRes.shape)\n","            if len(norRes.shape) == 0:\n","                norRes = tf.stack((norRes, 99))\n","                while tf.size(norRes) < 7:\n","                    norRes = tf.concat((norRes, [99]), axis=-1)\n","            else:\n","                while tf.size(norRes) < 7:\n","                    norRes = tf.concat((norRes, [99]), axis=-1)\n","\n","            AllPredictions.append(norRes)\n","\n","        for i in range(len(AllPredictions)):\n","            #print(batch_labels[i])\n","            for j in range(7):\n","                  # print(AllPredictions[i][j])\n","                  # print(batch_labels[i][j])\n","                  # print()\n","\n","\n","                  if AllPredictions[i][j] != batch_labels[i][j]:\n","                        #print(\"Entered hell yeah\")\n","                        wrongCharacters +=1\n","                  totalCharacters+=1\n","                  #print()\n","        else:\n","          continue\n","\n","\n","    print(wrongCharacters)\n","    print(totalCharacters)\n","\n","    errorRate = (wrongCharacters/totalCharacters)\n","    print(\"\\nError Rate: \",errorRate*100)\n","\n","    accuracy = 1-errorRate\n","\n","    print(\"Accuracy: \",accuracy*100)\n","\n","\n","\n","\n","\n","# indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n","# label = tf.strings.reduce_join(num_to_char(indices))\n","# label = label.numpy().decode(\"UTF-8\")\n","\n","getCharacterAccuracy(test_ds)\n"],"metadata":{"id":"hb2BDEie9K3t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Saving current model's weights"],"metadata":{"id":"2nypxlgm6qL2"}},{"cell_type":"code","source":["prediction_model.save('currBest2.h5')"],"metadata":{"id":"q8UfKkl8qw-S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing the model after saving"],"metadata":{"id":"bjQX-tBkb_6o"}},{"cell_type":"code","source":["loaded_model = tf.keras.models.load_model('currBest.h5',compile=False)"],"metadata":{"id":"TUgwlA58cENm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getCharacterAccuracy2(test_ds):\n","    # for batch in test_ds.take(1):\n","\n","    totalCharacters = 0\n","    wrongCharacters = 0\n","    batchNumber = 0\n","\n","    for batch in test_ds:\n","        # batch = tuple(test_ds.take(1))[0]\n","        batchNumber += 1\n","        batch_images, batch_labels = batch[\"image\"], batch[\"label\"]\n","        preds = loaded_model.predict(batch_images)\n","        pred_texts = decode_batch_predictions(preds)\n","\n","        input_len = np.ones(preds.shape[0]) * preds.shape[1]\n","        # Use greedy search. For complex tasks, you can use beam search.\n","        results = keras.backend.ctc_decode(preds, input_length=input_len, greedy=False, top_paths=1)[\n","            0\n","        ][0][:, :max_len]\n","\n","        AllPredictions = []\n","        # All predicitons\n","        for res in results:\n","            res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n","            res = tf.squeeze(res)\n","            norRes = tf.Variable(res)\n","\n","            # print(norRes.shape)\n","            if len(norRes.shape) == 0:\n","                norRes = tf.stack((norRes, 99))\n","                while tf.size(norRes) < 7:\n","                    norRes = tf.concat((norRes, [99]), axis=-1)\n","            else:\n","                while tf.size(norRes) < 7:\n","                    norRes = tf.concat((norRes, [99]), axis=-1)\n","\n","            AllPredictions.append(norRes)\n","\n","        for i in range(len(AllPredictions)):\n","            for j in range(7):\n","                  #print(AllPredictions[i][j])\n","                  #print(batch_labels[i][j])\n","\n","                  if AllPredictions[i][j] != batch_labels[i][j]:\n","                        #print(\"Entered hell yeah\")\n","                        wrongCharacters +=1\n","                  totalCharacters+=1\n","                  #print()\n","        else:\n","          continue\n","\n","\n","    errorRate = (wrongCharacters/totalCharacters)\n","    print(\"Error Rate: \",errorRate*100)\n","\n","    accuracy = 1-errorRate\n","\n","    print(\"Accuracy: \",accuracy*100)\n","\n","\n","\n","\n","\n","# indices = tf.gather(label, tf.where(tf.math.not_equal(label, padding_token)))\n","# label = tf.strings.reduce_join(num_to_char(indices))\n","# label = label.numpy().decode(\"UTF-8\")\n","\n","getCharacterAccuracy2(test_ds)\n"],"metadata":{"id":"37BujBHicEow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction_model = loaded_model"],"metadata":{"id":"nOX5C8G9Fj_N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Miscleanous code"],"metadata":{"id":"A-bW5WoXZvVr"}},{"cell_type":"markdown","source":["##### Debugging the character counting function"],"metadata":{"id":"COFRnrNBZzUw"}},{"cell_type":"code","source":["\n","def getCharacterAccuracy(test_ds):\n","  #for batch in test_ds.take(1):\n","  batch = tuple(test_ds.take(1))[0]\n","\n","  batch_images,batch_labels = batch[\"image\"],batch[\"label\"]\n","  preds = prediction_model.predict(batch_images)\n","  pred_texts = decode_batch_predictions(preds)\n","\n","  input_len = np.ones(preds.shape[0]) * preds.shape[1]\n","  # Use greedy search. For complex tasks, you can use beam search.\n","  results = keras.backend.ctc_decode(preds, input_length=input_len, greedy=True)[0][0][\n","     :, :max_len]\n","\n","  AllPredictions=[]\n","  #Get All predicitons for batch\n","  for res in results:\n","        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n","        res = tf.squeeze(res)\n","        norRes = tf.Variable(res)\n","\n","        if len(norRes.shape)==0:\n","          norRes=tf.stack((norRes,99))\n","          while tf.size(norRes)<7:\n","            norRes=tf.concat((norRes,[99]),axis=-1)\n","\n","        else:\n","            while tf.size(norRes)<7:\n","              norRes=tf.concat((norRes,[99]),axis=-1)\n","\n","        AllPredictions.append(norRes)\n","\n","  #Plot the batch with the prediction and the label as both arabic and vector notations\n","  _, ax = plt.subplots(4, 16, figsize=(100, 20))\n","\n","  for i in range(64):\n","        img = batch_images[i]\n","        img = tf.image.flip_left_right(img)\n","        img = tf.transpose(img, perm=[1, 0, 2])\n","        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n","        img = img[:, :, 0]\n","\n","        indices = tf.gather(batch_labels[i], tf.where(tf.math.not_equal(batch_labels[i], padding_token)))\n","        label = tf.strings.reduce_join(num_to_char(indices))\n","        label = label.numpy().decode(\"UTF-8\")\n","\n","\n","        ax[i // 16, i % 16].imshow(img, cmap=\"gray\")\n","        ax[i // 16, i % 16].set_title(str(AllPredictions[i])+\"\\nPrediction: \"+pred_texts[i][::-1])\n","        ax[i // 16, i % 16].set_xlabel(str(batch_labels[i])+\"\\nlabel: \"+label[::-1], labelpad=1)\n","        ax[i // 16, i % 16].axis(\"on\")\n","\n","  plt.show()\n","\n","\n","getCharacterAccuracy(test_ds)"],"metadata":{"id":"3oliJtm7Zw54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nRWJ_powxQOr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"tHl3MQTy4CMq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oO0sv21L32ca"},"outputs":[],"source":["import cv2 as cv\n","from google.colab.patches import cv_imshow\n","import numpy as np"]},{"cell_type":"markdown","source":["# Open Image"],"metadata":{"id":"PnqmFU2melQq"}},{"cell_type":"code","source":["image = cv.imread('Handwritten arabic text for testing.jpg')"],"metadata":{"id":"ciYQuN5kempk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv_imshow(image)"],"metadata":{"id":"CytA5-uJesh1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Resize Image"],"metadata":{"id":"IwrYYt4yiCwP"}},{"cell_type":"code","source":["h, w, c = image.shape #height width what's c? Color channels\n","\n","\n","\n","new_w = 720\n","ar = w/h #aspect ratio\n","new_h = int(new_w/ar)\n","\n","\n","image = cv.resize(image ,(new_w,new_h), interpolation = cv.INTER_CUBIC)\n","\n","cv_imshow(image)"],"metadata":{"id":"w-UrhIJHiEeW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Blur Image"],"metadata":{"id":"mBACiCQg4Eoc"}},{"cell_type":"code","source":["blurredImage = cv.bilateralFilter(image, 101,30,30)"],"metadata":{"id":"1jI3TkW_ek--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv_imshow(blurredImage)"],"metadata":{"id":"6ciiAdPRef9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Binarization Image"],"metadata":{"id":"nzS3oqC34u8E"}},{"cell_type":"code","source":["grayImage = cv.cvtColor(blurredImage, cv.COLOR_BGR2GRAY)"],"metadata":{"id":"Yo8xYUn-g06J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv_imshow(grayImage)"],"metadata":{"id":"HpRvtqCbg8uu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binarizedImage = cv.adaptiveThreshold(grayImage,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY_INV, 17, 20)\n","cv_imshow(binarizedImage)"],"metadata":{"id":"GLlNdEqxg-bF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dilation Segmenting"],"metadata":{"id":"mRSHzq4bhhLF"}},{"cell_type":"code","source":["kernel = np.ones((20,100), np.uint8) #The number might need to be changed\n","dialated = cv.dilate(binarizedImage,kernel,iterations= 1)\n","cv_imshow(dialated)"],"metadata":{"id":"KEROaNG1hQwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(contours,hierarchy) = cv.findContours(dialated.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n","#RETR_EXTERNAL means there are no contours within contours\n","sorted_contours_lines = contours"],"metadata":{"id":"FwX_SOKiic3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lineSegmented = image.copy()\n","\n","for ctr in sorted_contours_lines:\n","\n","  if cv.contourArea(ctr) < 1000: #removes noise but can be adjusted\n","      continue\n","  x,y,w,h = cv.boundingRect(ctr)\n","  cv.rectangle(lineSegmented,(x,y),(x+w,y+h),(0,0,250),2)\n","\n","cv_imshow(lineSegmented)"],"metadata":{"id":"f-wl44jyie3u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Word Segmentation"],"metadata":{"id":"ckyjl9pximsT"}},{"cell_type":"code","source":["kernel = np.ones((25,25), np.uint8) #The number might need to be changed\n","dialated2 = cv.dilate(binarizedImage,kernel,iterations= 1)\n","cv_imshow(dialated2)"],"metadata":{"id":"ruMrHBZai06h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img3 = image.copy()\n","words_list = []\n","\n","for line in sorted_contours_lines:\n","  if cv.contourArea(line) < 1000: #removes noise but can be adjusted\n","      continue\n","  x,y,w,h = cv.boundingRect(line)\n","  roi_line = dialated2[y:y+w, x:x+w]\n","  #cv_imshow(roi_line)\n","\n","  #Draw contours on each word\n","  (cnt,hierarchy) = cv.findContours(roi_line.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n","  #RETR_EXTERNAL means there are no contours within contours\n","  sorted_contours_words = sorted(cnt, key = lambda cntr: cv.boundingRect(cntr)[0], reverse=True) #Contains (x,y,w,h) x and y locations and width and height\n","\n","  for word in sorted_contours_words:\n","\n","    if cv.contourArea(word) < 600: #removes noise\n","      continue\n","    x2,y2,w2,h2 = cv.boundingRect(word)\n","    words_list.append([x+x2,y+y2,x+x2+w2,y+y2+h2])\n","    #print([x+x2,y+y2,x+x2+w2,y+y2+h2])\n","    cv.rectangle(img3,(x+x2,y+y2),(x+x2+w2,y+y2+h2),(255,255,100),2)\n","    #cv_imshow(img3)\n","\n","\n","cv_imshow(img3)"],"metadata":{"id":"7hlVPaRnjKch"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Store each words from top to bottom and right to left."],"metadata":{"id":"B38NgcOPuoYN"}},{"cell_type":"code","source":["words_list = []\n","\n","for ctr in sorted_contours_lines[::-1]:\n","\n","  if cv.contourArea(ctr) < 1000: #removes noise but can be adjusted\n","      continue\n","  x,y,w,h = cv.boundingRect(ctr)\n","  line = dialated2 [y:y+h,x:x+w]\n","\n","  (cnt,hierarchy) = cv.findContours(line.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n","\n","  sorted_contours_words = sorted(cnt, key = lambda cntr: cv.boundingRect(cntr)[0], reverse=True)\n","\n","  for word in sorted_contours_words:\n","\n","    if cv.contourArea(word) < 600: #removes noise\n","      continue\n","    x2,y2,w2,h2 = cv.boundingRect(word)\n","    words_list.append([x+x2,y+y2,x+x2+w2,y+y2+h2])\n","\n","\n"],"metadata":{"id":"KIkKGH_YsYCS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Store each word separtely"],"metadata":{"id":"yjRyvZL8m8k4"}},{"cell_type":"code","source":["words=[]\n","\n","for word in words_list:\n","  word = image[ word[1]:word[3], word[0]:word[2]]\n","  words.append(word)\n","  cv_imshow(word)"],"metadata":{"id":"9kXQObPfnAJN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Resize all of the words"],"metadata":{"id":"UrIU2aHYujTL"}},{"cell_type":"code","source":["def resizeImage(word):\n","\n","  word = cv.resize(word,(64,32),interpolation=cv.INTER_CUBIC)\n","\n","  return word"],"metadata":{"id":"X3PI9v_fwhTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resized_words = [ resizeImage(word) for word in words]"],"metadata":{"id":"x309W35qvpBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word in resized_words:\n","  cv_imshow(word)"],"metadata":{"id":"8mSycSC3wXyE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Binarize the Resized words"],"metadata":{"id":"v4qOBDRwxCN0"}},{"cell_type":"code","source":["def convertToGray(image):\n","\n","  image = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n","\n","  return image"],"metadata":{"id":"Gjfk2eJ2xE28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gray_words = [ convertToGray(word) for word in resized_words]"],"metadata":{"id":"j1F3aBj6xNtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word in gray_words:\n","  cv_imshow(word)"],"metadata":{"id":"o0QfTKBTxRx_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def binarizeWords(image):\n","  image = cv.adaptiveThreshold(image,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY_INV,17, 10)\n","\n","  return image"],"metadata":{"id":"WiapmrZpy27u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binary_words = [ binarizeWords(word) for word in gray_words]"],"metadata":{"id":"Ox6_Cf-PxSi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for word in binary_words:\n","  cv_imshow(word)"],"metadata":{"id":"qhmE6l1ezAvM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","\n","# if not os.path.exists(\"./temp\"):\n","#   os.mkdir(\"./temp\")\n","\n","# i=0\n","# for word in binary_words:\n","#   cv.imwrite(\"./temp/\"+str(i)+\".jpg\",word)\n","#   i+=1"],"metadata":{"id":"qczY8KGFfpXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n","from tensorflow import keras"],"metadata":{"id":"b7UECufZzFki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","image = tf.cast(binary_words[2], tf.float32) / 255.0"],"metadata":{"id":"NiRMYfMjayEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = binary_words[5]"],"metadata":{"id":"I_6ofMFuoGSb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i=-10\n","\n","image = tf.cast(binary_words[i], tf.float32) / 255.0\n","cv_imshow(binary_words[i])\n","\n","tempImage= tf.transpose(image)\n","tempImage = np.expand_dims(tempImage,-1)\n","\n","preds = prediction_model.predict(np.array([tempImage]))\n","characters = {'ن', 'س', 'ة', 'ك', '.', 'ء', '،', 'ف', 'ه', 'ب', 'خ', 'ؤ', 'غ', 'ز', 'ق', 'ث', 'ح', 'ذ', 'ئ', 'آ', 'إ', 'ض', 'ش', 'م', 'ر', 'ص', 'ا', 'ٍ', ':', 'و', 'أ', 'ظ', 'ل', 'ج', 'د', 'ع', 'ط', 'ت', 'ي'}\n","\n","\n","char_to_num = StringLookup(vocabulary=list(sorted(characters)), mask_token=None)\n","\n","\n","num_to_char = StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",")\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","\n","def decode_batch_predictions(pred):\n","    max_len=7\n","    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n","    # Use greedy search. For complex tasks, you can use beam search.\n","    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=False)[0][0][\n","        :, :max_len\n","    ]\n","    # Iterate over the results and get back the text.\n","    output_text = []\n","    #print(results)\n","    for res in results:\n","        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n","        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"UTF-8\")\n","        output_text.append(res)\n","\n","    return output_text\n","pred_texts = decode_batch_predictions(preds)\n","pred_texts"],"metadata":{"id":"_zvC8eL5OpIq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V28","private_outputs":true,"collapsed_sections":["nmmNQUUjdjOJ","A-bW5WoXZvVr"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}